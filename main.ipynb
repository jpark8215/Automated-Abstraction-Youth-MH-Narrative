{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1d46ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading punkt...\n",
      "Successfully downloaded punkt\n",
      "Downloading stopwords...\n",
      "Successfully downloaded stopwords\n",
      "Downloading wordnet...\n",
      "Successfully downloaded wordnet\n",
      "Downloading omw-1.4...\n",
      "Successfully downloaded omw-1.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download required NLTK data\n",
    "required_nltk_resources = ['punkt', 'stopwords', 'wordnet', 'omw-1.4']\n",
    "\n",
    "def download_nltk_resources():\n",
    "    \"\"\"Download required NLTK resources with error handling.\"\"\"\n",
    "    for resource in required_nltk_resources:\n",
    "        try:\n",
    "            print(f\"Downloading {resource}...\")\n",
    "            nltk.download(resource, quiet=True)\n",
    "            print(f\"Successfully downloaded {resource}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {resource}: {e}\")\n",
    "            raise\n",
    "\n",
    "            \n",
    "# Download resources\n",
    "try:\n",
    "    download_nltk_resources()\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download required NLTK resources: {e}\")\n",
    "    raise\n",
    "\n",
    "    \n",
    "# Load the data\n",
    "try:\n",
    "    features_df = pd.read_csv('data/train_features.csv')\n",
    "    labels_df = pd.read_csv('data/train_labels.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data files: {e}\")\n",
    "    raise\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3137f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by converting to lowercase, removing special characters,\n",
    "    tokenizing, removing stop words, and lemmatizing.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to preprocess\n",
    "        \n",
    "    Returns:\n",
    "        str: Preprocessed text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to lowercase and handle non-string input\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove special characters and punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "        # Tokenize the text\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stop words and lemmatize\n",
    "        processed_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "        \n",
    "        return ' '.join(processed_tokens)\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing text: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef5dfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting text preprocessing...\n",
      "Processing row 0/4000\n",
      "Processing row 1000/4000\n",
      "Processing row 2000/4000\n",
      "Processing row 3000/4000\n",
      "\n",
      "Merging features and labels...\n",
      "\n",
      "First few rows of processed data:\n",
      "    uid                                processed_narrative\n",
      "0  aaaf  v xx xx shot motor vehiclethe v mother called ...\n",
      "1  aaby  v xxxx v found basement residence hanging stra...\n",
      "2  aacl  v xxxx v found residence unresponsive result g...\n",
      "3  aacn  victim xx xx recently returned village residin...\n",
      "4  aadb  xx xx v found deceased home grandparent hangin...\n",
      "\n",
      "Saving processed data...\n",
      "Data preparation complete. Processed data saved to 'processed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # Combine and preprocess NarrativeLE and NarrativeCME\n",
    "    print(\"Starting text preprocessing...\")\n",
    "    features_df['processed_narrative'] = (features_df['NarrativeLE'].fillna('') + ' ' + \n",
    "                                        features_df['NarrativeCME'].fillna(''))\n",
    "    \n",
    "    \n",
    "    # Process texts with progress indicator\n",
    "    total_rows = len(features_df)\n",
    "    for idx, row in enumerate(features_df['processed_narrative']):\n",
    "        if idx % 1000 == 0:  # Print progress every 1000 rows\n",
    "            print(f\"Processing row {idx}/{total_rows}\")\n",
    "        features_df.at[idx, 'processed_narrative'] = preprocess_text(row)\n",
    "\n",
    "        \n",
    "    # Merge features and labels\n",
    "    print(\"\\nMerging features and labels...\")\n",
    "    merged_df = pd.merge(features_df, labels_df, on='uid')\n",
    "\n",
    "    \n",
    "    # Display the first few rows of the processed data\n",
    "    print(\"\\nFirst few rows of processed data:\")\n",
    "    print(merged_df[['uid', 'processed_narrative']].head())\n",
    "\n",
    "    \n",
    "    # Save the processed data\n",
    "    print(\"\\nSaving processed data...\")\n",
    "    merged_df.to_csv('processed_data.csv', index=False)\n",
    "    print(\"Data preparation complete. Processed data saved to 'processed_data.csv'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in data processing pipeline: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd7f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def prepare_submission(processed_data_path, submission_format_path='data\\submission_format.csv'):\n",
    "    \"\"\"\n",
    "    Prepare processed data according to the required submission format with enhanced NA handling.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the processed data and submission format\n",
    "        print(\"Loading data files...\")\n",
    "        processed_df = pd.read_csv(processed_data_path)\n",
    "        submission_template = pd.read_csv(submission_format_path)\n",
    "        \n",
    "        print(f\"Processed data shape: {processed_df.shape}\")\n",
    "        print(f\"Template shape: {submission_template.shape}\")\n",
    "        \n",
    "        # Check for NA values in processed data\n",
    "        print(\"\\nNA values in processed data:\")\n",
    "        print(processed_df.isna().sum())\n",
    "        \n",
    "        binary_columns = [\n",
    "            'DepressedMood', 'MentalIllnessTreatmentCurrnt', 'HistoryMentalIllnessTreatmnt',\n",
    "            'SuicideAttemptHistory', 'SuicideThoughtHistory', 'SubstanceAbuseProblem',\n",
    "            'MentalHealthProblem', 'DiagnosisAnxiety', 'DiagnosisDepressionDysthymia',\n",
    "            'DiagnosisBipolar', 'DiagnosisAdhd', 'IntimatePartnerProblem',\n",
    "            'FamilyRelationship', 'Argument', 'SchoolProblem', 'RecentCriminalLegalProblem',\n",
    "            'SuicideNote', 'SuicideIntentDisclosed', 'DisclosedToIntimatePartner',\n",
    "            'DisclosedToOtherFamilyMember', 'DisclosedToFriend'\n",
    "        ]\n",
    "        \n",
    "        categorical_columns = ['InjuryLocationType', 'WeaponType1']\n",
    "        \n",
    "        # Create submission dataframe with same structure as template\n",
    "        submission_df = pd.DataFrame()\n",
    "        submission_df['uid'] = submission_template['uid']\n",
    "        \n",
    "        # Handle binary columns with more aggressive NA handling\n",
    "        print(\"\\nProcessing binary columns...\")\n",
    "        for col in binary_columns:\n",
    "            try:\n",
    "                if col in processed_df.columns:\n",
    "                    # Replace any non-finite values with 0\n",
    "                    processed_df[col] = processed_df[col].replace([np.inf, -np.inf], np.nan)\n",
    "                    processed_df[col] = processed_df[col].fillna(0)\n",
    "                    # Convert to integer through boolean to ensure 0/1 values\n",
    "                    submission_df[col] = processed_df[col].astype(float).fillna(0).astype(bool).astype(int)\n",
    "                    print(f\"Processed {col} - unique values: {submission_df[col].unique()}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Column {col} not found in processed data\")\n",
    "                    submission_df[col] = 0\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing binary column {col}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        # Handle categorical columns with more aggressive NA handling\n",
    "        print(\"\\nProcessing categorical columns...\")\n",
    "        for col in categorical_columns:\n",
    "            try:\n",
    "                if col in processed_df.columns:\n",
    "                    # Replace any non-finite values\n",
    "                    processed_df[col] = processed_df[col].replace([np.inf, -np.inf], np.nan)\n",
    "                    \n",
    "                    if col == 'InjuryLocationType':\n",
    "                        processed_df[col] = processed_df[col].fillna(1)\n",
    "                        submission_df[col] = processed_df[col].astype(float).fillna(1).astype(int)\n",
    "                        submission_df.loc[~submission_df[col].between(1, 6), col] = 1\n",
    "                    elif col == 'WeaponType1':\n",
    "                        processed_df[col] = processed_df[col].fillna(12)\n",
    "                        submission_df[col] = processed_df[col].astype(float).fillna(12).astype(int)\n",
    "                        submission_df.loc[~submission_df[col].between(1, 12), col] = 12\n",
    "                    \n",
    "                    print(f\"Processed {col} - unique values: {submission_df[col].unique()}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Column {col} not found in processed data\")\n",
    "                    submission_df[col] = 1 if col == 'InjuryLocationType' else 12\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing categorical column {col}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        # Verify data types\n",
    "        print(\"\\nVerifying data types...\")\n",
    "        submission_df['uid'] = submission_df['uid'].astype(str)\n",
    "        for col in binary_columns + categorical_columns:\n",
    "            submission_df[col] = pd.to_numeric(submission_df[col], errors='coerce').fillna(0).astype(int)\n",
    "        \n",
    "        # Ensure column order matches template\n",
    "        submission_df = submission_df[submission_template.columns]\n",
    "        \n",
    "        # Final verifications\n",
    "        print(\"\\nPerforming final verifications...\")\n",
    "        print(\"Checking for any remaining NA values:\")\n",
    "        print(submission_df.isna().sum())\n",
    "        \n",
    "        assert len(submission_df) == len(submission_template), \"Submission has incorrect number of rows\"\n",
    "        \n",
    "        return submission_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error preparing submission: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8516aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting submission preparation...\n",
      "Current working directory: C:\\Users\\jpark\\Downloads\n",
      "Warning: submission_format.csv not found in current directory\n",
      "Loading data files...\n",
      "Processed data shape: (4000, 27)\n",
      "Template shape: (1000, 24)\n",
      "\n",
      "NA values in processed data:\n",
      "uid                             0\n",
      "NarrativeLE                     0\n",
      "NarrativeCME                    0\n",
      "processed_narrative             0\n",
      "DepressedMood                   0\n",
      "MentalIllnessTreatmentCurrnt    0\n",
      "HistoryMentalIllnessTreatmnt    0\n",
      "SuicideAttemptHistory           0\n",
      "SuicideThoughtHistory           0\n",
      "SubstanceAbuseProblem           0\n",
      "MentalHealthProblem             0\n",
      "DiagnosisAnxiety                0\n",
      "DiagnosisDepressionDysthymia    0\n",
      "DiagnosisBipolar                0\n",
      "DiagnosisAdhd                   0\n",
      "IntimatePartnerProblem          0\n",
      "FamilyRelationship              0\n",
      "Argument                        0\n",
      "SchoolProblem                   0\n",
      "RecentCriminalLegalProblem      0\n",
      "SuicideNote                     0\n",
      "SuicideIntentDisclosed          0\n",
      "DisclosedToIntimatePartner      0\n",
      "DisclosedToOtherFamilyMember    0\n",
      "DisclosedToFriend               0\n",
      "InjuryLocationType              0\n",
      "WeaponType1                     0\n",
      "dtype: int64\n",
      "\n",
      "Processing binary columns...\n",
      "Processed DepressedMood - unique values: [0 1]\n",
      "Processed MentalIllnessTreatmentCurrnt - unique values: [0 1]\n",
      "Processed HistoryMentalIllnessTreatmnt - unique values: [0 1]\n",
      "Processed SuicideAttemptHistory - unique values: [0 1]\n",
      "Processed SuicideThoughtHistory - unique values: [1 0]\n",
      "Processed SubstanceAbuseProblem - unique values: [0 1]\n",
      "Processed MentalHealthProblem - unique values: [0 1]\n",
      "Processed DiagnosisAnxiety - unique values: [0 1]\n",
      "Processed DiagnosisDepressionDysthymia - unique values: [0 1]\n",
      "Processed DiagnosisBipolar - unique values: [0 1]\n",
      "Processed DiagnosisAdhd - unique values: [0 1]\n",
      "Processed IntimatePartnerProblem - unique values: [0 1]\n",
      "Processed FamilyRelationship - unique values: [0 1]\n",
      "Processed Argument - unique values: [0 1]\n",
      "Processed SchoolProblem - unique values: [0 1]\n",
      "Processed RecentCriminalLegalProblem - unique values: [0 1]\n",
      "Processed SuicideNote - unique values: [0 1]\n",
      "Processed SuicideIntentDisclosed - unique values: [1 0]\n",
      "Processed DisclosedToIntimatePartner - unique values: [0 1]\n",
      "Processed DisclosedToOtherFamilyMember - unique values: [1 0]\n",
      "Processed DisclosedToFriend - unique values: [0 1]\n",
      "\n",
      "Processing categorical columns...\n",
      "Processed InjuryLocationType - unique values: [2 1 3 6 4 5]\n",
      "Processed WeaponType1 - unique values: [ 5  6  3  9  4  8 10  7  2 11]\n",
      "\n",
      "Verifying data types...\n",
      "\n",
      "Performing final verifications...\n",
      "Checking for any remaining NA values:\n",
      "uid                             0\n",
      "DepressedMood                   0\n",
      "MentalIllnessTreatmentCurrnt    0\n",
      "HistoryMentalIllnessTreatmnt    0\n",
      "SuicideAttemptHistory           0\n",
      "SuicideThoughtHistory           0\n",
      "SubstanceAbuseProblem           0\n",
      "MentalHealthProblem             0\n",
      "DiagnosisAnxiety                0\n",
      "DiagnosisDepressionDysthymia    0\n",
      "DiagnosisBipolar                0\n",
      "DiagnosisAdhd                   0\n",
      "IntimatePartnerProblem          0\n",
      "FamilyRelationship              0\n",
      "Argument                        0\n",
      "SchoolProblem                   0\n",
      "RecentCriminalLegalProblem      0\n",
      "SuicideNote                     0\n",
      "SuicideIntentDisclosed          0\n",
      "DisclosedToIntimatePartner      0\n",
      "DisclosedToOtherFamilyMember    0\n",
      "DisclosedToFriend               0\n",
      "InjuryLocationType              0\n",
      "WeaponType1                     0\n",
      "dtype: int64\n",
      "Clearing contents of submission.csv as it is not empty...\n",
      "Submission file saved as submission.csv\n",
      "\n",
      "Processed data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 27 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   uid                           4000 non-null   object\n",
      " 1   NarrativeLE                   4000 non-null   object\n",
      " 2   NarrativeCME                  4000 non-null   object\n",
      " 3   processed_narrative           4000 non-null   object\n",
      " 4   DepressedMood                 4000 non-null   int64 \n",
      " 5   MentalIllnessTreatmentCurrnt  4000 non-null   int64 \n",
      " 6   HistoryMentalIllnessTreatmnt  4000 non-null   int64 \n",
      " 7   SuicideAttemptHistory         4000 non-null   int64 \n",
      " 8   SuicideThoughtHistory         4000 non-null   int64 \n",
      " 9   SubstanceAbuseProblem         4000 non-null   int64 \n",
      " 10  MentalHealthProblem           4000 non-null   int64 \n",
      " 11  DiagnosisAnxiety              4000 non-null   int64 \n",
      " 12  DiagnosisDepressionDysthymia  4000 non-null   int64 \n",
      " 13  DiagnosisBipolar              4000 non-null   int64 \n",
      " 14  DiagnosisAdhd                 4000 non-null   int64 \n",
      " 15  IntimatePartnerProblem        4000 non-null   int64 \n",
      " 16  FamilyRelationship            4000 non-null   int64 \n",
      " 17  Argument                      4000 non-null   int64 \n",
      " 18  SchoolProblem                 4000 non-null   int64 \n",
      " 19  RecentCriminalLegalProblem    4000 non-null   int64 \n",
      " 20  SuicideNote                   4000 non-null   int64 \n",
      " 21  SuicideIntentDisclosed        4000 non-null   int64 \n",
      " 22  DisclosedToIntimatePartner    4000 non-null   int64 \n",
      " 23  DisclosedToOtherFamilyMember  4000 non-null   int64 \n",
      " 24  DisclosedToFriend             4000 non-null   int64 \n",
      " 25  InjuryLocationType            4000 non-null   int64 \n",
      " 26  WeaponType1                   4000 non-null   int64 \n",
      "dtypes: int64(23), object(4)\n",
      "memory usage: 843.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def save_submission(submission_df, file_name='submission.csv'):\n",
    "    \"\"\"\n",
    "    Save the submission dataframe to a CSV file. Clears the file if it's not empty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the file exists and is not empty\n",
    "        if os.path.exists(file_name):\n",
    "            if os.path.getsize(file_name) > 0:\n",
    "                print(f\"Clearing contents of {file_name} as it is not empty...\")\n",
    "                open(file_name, 'w').close()  # Clear the file\n",
    "        \n",
    "        # Save the submission DataFrame to the cleared (or new) file\n",
    "        submission_df.to_csv(file_name, index=False)\n",
    "        print(f\"Submission file saved as {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving submission: {e}\")\n",
    "        raise\n",
    "\n",
    "# Example of calling the functions\n",
    "try:\n",
    "    print(\"Starting submission preparation...\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "    # Check if files exist\n",
    "    if not os.path.exists('processed_data.csv'):\n",
    "        print(\"Warning: processed_data.csv not found in current directory\")\n",
    "    if not os.path.exists('submission_format.csv'):\n",
    "        print(\"Warning: submission_format.csv not found in current directory\")\n",
    "    \n",
    "    submission_df = prepare_submission('processed_data.csv')\n",
    "    save_submission(submission_df)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in submission pipeline: {e}\")\n",
    "\n",
    "    # Print detailed information about the data if available\n",
    "    if 'submission_df' in locals():\n",
    "        print(\"\\nSubmission DataFrame Info:\")\n",
    "        print(submission_df.info())\n",
    "\n",
    "# Check processed data if it exists\n",
    "if os.path.exists('processed_data.csv'):\n",
    "    df = pd.read_csv('processed_data.csv')\n",
    "    print(\"\\nProcessed data info:\")\n",
    "    print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ded6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
